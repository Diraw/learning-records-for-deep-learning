> AlexNet.pthè¿™ä¸ªæ–‡ä»¶æœ‰55Mï¼ŒGitHubæœ€å¤šä¸Šä¼ 50Mçš„æ–‡ä»¶ï¼Œæ‰€ä»¥è¿™ä¸ªæƒé‡æ–‡ä»¶æŸåäº†ï¼Œæ‡’å¾—å†pullä¸‹æ¥åˆ é™¤äº†ğŸ˜‚

> ä¸»è¦æ˜¯åº”è¯¥æ²¡äººä¼šæ¥çœ‹æˆ‘çš„repoå§hhh
# AlexNet
æœ¬æ–‡ä¸ºæœ¬äººå­¦ä¹ æ·±åº¦å­¦ä¹ æ‰€åšï¼Œæ—¶é—´24/07/19

çœ‹çš„è§†é¢‘æ˜¯bç«™upä¸»éœ¹é›³å§å•¦Wz [2.1 pytorchå®˜æ–¹demo(Lenet)](https://www.bilibili.com/video/BV1W7411T7qc/?spm_id_from=333.788&vd_source=0ac3c820aa67ba88616bd91e7b19b3d6)

ä»£ç ä¹Ÿæ˜¯ä»–æä¾›çš„ [ä»–çš„GitHubé“¾æ¥](https://github.com/WZMIAOMIAO/deep-learning-for-image-processing)

è¶Šå­¦è¶Šè§‰å¾—è¿™ä¸ªupè®²çš„çœŸæŒºå¥½çš„ï¼Œé™¤äº†çŸ¥è¯†è®²çš„å¾ˆæ¸…æ™°ï¼Œåœ¨è§†é¢‘é‡Œä¼šéšç€ç³»åˆ—çš„æ·±å…¥ï¼Œé€æ¸åŠ ä¸Šä¸€äº›é¡¹ç›®å·¥ç¨‹çš„ä¸œè¥¿è¿›å»ï¼Œåƒè¿™ä¸ªé¡¹ç›®é‡Œå°±æœ‰æ–­è¨€ã€æ–‡ä»¶å¤¹æ„æˆã€è·‘ä¸€æ¬¡æ¨¡å‹çš„æ—¶é—´è¿™äº›æœ‰ç”¨çš„å°æŠ€å·§çš„åŠ å…¥ï¼ŒçœŸçš„è®²çš„å¾ˆå¥½ï¼Œååˆ†æ”¶ç›Š
# ä¸€ã€æ¨¡å‹çš„ä»£ç 
```python
class AlexNet(nn.Module):
    def __init__(self, num_classes=1000, init_weights=False):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2),  
            # input[3, 224, 224]  output[48, 55, 55]
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),                  
            # output[48, 27, 27]
            nn.Conv2d(48, 128, kernel_size=5, padding=2),           
            # output[128, 27, 27]
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),                  
            # output[128, 13, 13]
            nn.Conv2d(128, 192, kernel_size=3, padding=1),          
            # output[192, 13, 13]
            nn.ReLU(inplace=True),
            nn.Conv2d(192, 192, kernel_size=3, padding=1),          
            # output[192, 13, 13]
            nn.ReLU(inplace=True),
            nn.Conv2d(192, 128, kernel_size=3, padding=1),          
            # output[128, 13, 13]
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),                  
            # output[128, 6, 6]
        )
        self.classifier = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Linear(128 * 6 * 6, 2048),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5),
            nn.Linear(2048, 2048),
            nn.ReLU(inplace=True),
            nn.Linear(2048, num_classes),
        )
        if init_weights:
            self._initialize_weights()
```
`nn.Sequential()`å¯ä»¥å°†æ‰€æœ‰æ¨¡å—æ‰“åŒ…ï¼Œè¿™æ ·ä¼šå¾ˆæ–¹ä¾¿

`self.features` ç‰¹å¾æå–

`self.classifier`åˆ†ç±»å™¨

`nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2)`æ·±åº¦3ï¼Œå¤§å°48ï¼Œå·ç§¯æ ¸å¤§å°11ï¼Œæ­¥è·4ï¼Œpadding 2ï¼Œå‰ä¸¤é¡¹æ˜¯ä½ç½®ä¼ å‚ï¼Œåä¸‰é¡¹æ˜¯å…³é”®å­—ä¼ å‚ï¼Œè¿™æ ·ä»£ç æ›´æ¸…æ™°ä¸€ç‚¹ï¼ˆå¯¹æˆ‘è¿™ç§åˆå­¦è€…æ¥è¯´æ›´å¥½ç†è§£hhhï¼‰
```python
class Conv1d(_ConvNd):
    def __init__(
        self,
        in_channels: int, #è¾“å…¥çš„æ·±åº¦
        out_channels: int, #ä½¿ç”¨å·ç§¯æ ¸çš„ä¸ªæ•°
        kernel_size: _size_2_t, #å·ç§¯æ ¸çš„å¤§å°
        stride: _size_2_t = 1, #æ­¥é•¿ã€æ­¥è·
        padding: Union[str, _size_2_t] = 0, #padding å››å‘¨è¡¥0å¤„ç†
        dilation: _size_2_t = 1,
        groups: int = 1,
        bias: bool = True, #biasåç½®ï¼Œé»˜è®¤ä½¿ç”¨
        padding_mode: str = 'zeros',  # TODO: refine this type
        device=None,
        dtype=None
```
paddingè¿™é‡Œæ˜¯ç›´æ¥å†™æˆçš„2ï¼Œè§†é¢‘é‡Œæœ‰ï¼Œå’Œè®ºæ–‡ä¸å¤ªå‡†ç¡®ï¼Œä½†æ–¹ä¾¿ï¼Œå› ä¸ºpytorchä¼šè‡ªåŠ¨å¤„ç†ï¼Œè¿™å°±å¤Ÿäº†

`nn.ReLU(inplace=True)`è¿™ä¸ªinplaceä¸ºTrueçš„è¯èƒ½å¤Ÿæé«˜æ€§èƒ½

`nn.Dropout(p=0.5)` dropoutæ“ä½œï¼Œpæ˜¯éšæœºå¤±æ´»çš„æ¯”ä¾‹ï¼Œé»˜è®¤ä¸º0.5

`nn.Linear(128 * 6 * 6, 2048)`
```python
class Linear(Module):
    __constants__ = ['in_features', 'out_features']
    in_features: int
    out_features: int
    weight: Tensor

    def __init__(self,
                 in_features: int, 
                 out_features: int, 
                 bias: bool = True,
                 device=None, dtype=None) -> None:
        factory_kwargs = {'device': device, 'dtype': dtype}
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
```
linearå®šä¹‰å…¨è¿æ¥å±‚ï¼Œå¯ä»¥çœ‹åˆ°ç¬¬ä¸€ä¸ªå‚æ•°ä¸ºè¾“å‡ºç¥ç»å…ƒä¸ªæ•°ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯è¾“å‡ºç¥ç»å…ƒä¸ªæ•°

`nn.Linear(2048, num_classes)`å¯ä»¥çœ‹åˆ°æœ€ç»ˆçš„è¾“å‡ºä¸ªæ•°æ˜¯num_classesï¼Œè¿™ä¸ªæ˜¯åœ¨æœ€å‰é¢å®šä¹‰å‡½æ•°é‡Œ
```python
class AlexNet(nn.Module):
    def __init__(self, num_classes=1000, init_weights=False):
```
ä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬å®šä¹‰æ¨¡å‹çš„æ—¶å€™å¯ä»¥ä¼ å‚ä¿®æ”¹mun_classesï¼Œå³æœ€ç»ˆçš„è¾“å‡ºå€¼ï¼Œè¿™ä¸ªæ–¹ä¾¿æˆ‘ä»¬åç»­ç”¨è¿™ä¸ªæ¨¡å‹å»è®­ç»ƒè‡ªå·±æƒ³è®­ç»ƒçš„æ•°æ®é›†

```python
if init_weights:
    self._initialize_weights()
```
å®šä¹‰æ¨¡å‹çš„ç¬¬äºŒä¸ªå‚æ•°init_weight åˆå§‹åŒ–æƒé‡ï¼Œå¦‚æœä¸ºTrueçš„è¯ï¼Œè¿›å…¥ä¸‹é¢ä»£ç 
```python
def _initialize_weights(self):
    for m in self.modules():
        if isinstance(m, nn.Conv2d):
            nn.init.kaiming_normal_(
                m.weight, mode='fan_out', 
                nonlinearity='relu')
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.Linear):
            nn.init.normal_(m.weight, 0, 0.01)
            nn.init.constant_(m.bias, 0)
```
å…¶ä¸­ç”¨åˆ°äº†`self.modules()`ï¼Œæˆ‘ä»¬è¿›å…¥ä»–çš„ä»£ç çœ‹çœ‹
```python
def modules(self) -> Iterator['Module']:
    r"""Return an iterator over all modules in the network."""
```
ä¹Ÿå°±æ˜¯è¯´`self.modules()`ä¼šè¿”å›ä¸€ä¸ªè¿­ä»£å™¨ï¼Œè¿™ä¸ªè¿­ä»£å™¨ä¼šéå†ç½‘ç»œä¸­æ‰€æœ‰çš„æ¨¡å—ï¼Œéå†æˆ‘ä»¬åœ¨featureå®šä¹‰çš„æ‰€æœ‰å±‚ç»“æ„
```python
if isinstance(m, nn.Conv2d):
    nn.init.kaiming_normal_(
        m.weight, mode='fan_out', 
        nonlinearity='relu')
```
å¦‚æœè¯¥å±‚æ˜¯`nn.Conv2d`çš„è¯ï¼Œå°±ç”¨`nn.init.kaiming_normal_`è¿™ä¸ªåˆå§‹åŒ–æ–¹æ³•å»åˆå§‹åŒ–mä¸­çš„æƒé‡`m.weight`
```python
if m.bias is not None:
    nn.init.constant_(m.bias, 0)
```
å¦‚æœå®ƒçš„åç½®ä¸ä¸ºç©ºçš„è¯ï¼Œå°±ç”¨0è¿›è¡Œåˆå§‹åŒ–
```python
nn.init.normal_(m.weight, 0, 0.01)
```
æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ï¼Œå‡å€¼ä¸º0ï¼Œæ–¹å·®0.01

ä½†å…¶å®æˆ‘ä»¬ä¸ç”¨å»ç®¡è¿™ä¸ª`init_weights=False`ï¼Œè‡³å°‘åœ¨å½“å‰ç‰ˆæœ¬pytorchä¼šè‡ªåŠ¨å»åˆå§‹åŒ–æƒé‡
```python
def forward(self, x):
    x = self.features(x)
    x = torch.flatten(x, start_dim=1)
    x = self.classifier(x)
    return x
```
forwardå®šä¹‰æ­£å‘ä¼ æ’­è¿‡ç¨‹

`x = torch.flatten(x, start_dim=1)`å¯¹å›¾åƒè¿›è¡Œå±•å¹³

start_dim=1è¡¨ç¤ºä»0ç»´ä¹‹åå±•å¹³ï¼Œå› ä¸ºtensorçš„ç¬¬ä¸€ä¸ªç»´åº¦æ˜¯batchï¼Œæˆ‘ä»¬æŠŠåé¢çš„æ·±åº¦é«˜åº¦å®½åº¦å±•å¼€

ä¹Ÿå¯ä»¥å’Œlenetç½‘ç»œçš„ä»£ç ä¸€æ ·ï¼Œç”¨viewè¿›è¡Œå±•å¹³

# äºŒã€è®­ç»ƒçš„ä»£ç 
```python
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print("using {} device.".format(device))
```
é€‰æ‹©ä½¿ç”¨GPUè¿˜æ˜¯CPUï¼Œç„¶åæ‰“å°ä¿¡æ¯
```python
data_transform = {
    "train": transforms.Compose([transforms.RandomResizedCrop(224),
                                 transforms.RandomHorizontalFlip(),
                                 transforms.ToTensor(),
                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),
    "val": transforms.Compose([transforms.Resize((224, 224)),  
                               # cannot 224, must (224, 224)
                               transforms.ToTensor(),
                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}
```
å®šä¹‰é¢„å¤„ç†å‡½æ•°

`transforms.RandomResizedCrop(224)`éšæœºè£å‰ªä¸º $224\times 224$ çš„å¤§å°

`transform.RandomHorizontalFlip()`åè½¬æ“ä½œè¿›è¡Œæ•°æ®å¢å¼º

`transforms.Resize((224, 224))`å¯¹è®­ç»ƒé›†æ˜¯éšæœºè£å‰ªï¼Œå¯¹éªŒè¯é›†æ˜¯resizeï¼Œå¹¶ä¸”è¿™é‡Œè¦è¾“å…¥ä¸¤ä¸ªå˜é‡

`os.getcwd()`è·å¾—å½“å‰æ‰€åœ¨ç›®å½•

`os.path.join(os.getcwd(), "../..")`å°†å½“å‰ç›®å½•å’Œé‚£ä¸ªå­—ç¬¦ä¸²è¿åœ¨ä¸€èµ·ï¼Œä¸¤ä¸ª`..`ä»£è¡¨è¿”å›ä¸Šä¸Šçº§ç›®å½•ï¼Œè¿™é‡Œçš„åšæ³•æœ‰åˆ©äºé¡¹ç›®å·¥ç¨‹

`data_root = os.path.abspath(os.path.join(os.getcwd(), "../..")) `
dataæ ¹ç›®å½•

`image_path = os.path.join(data_root, "data_set", "flower_data")`
è·å¾—å›¾ç‰‡çš„ä½ç½®ï¼Œåé¢ä¹Ÿå¯ä»¥æ˜¯`"/data_set/flower_data/"`

`os.path.exists(image_path)`:æ£€æŸ¥ image_path æ˜¯å¦å­˜åœ¨

```python
train_dataset = datasets.ImageFolder(
                    root=os.path.join(image_path, "train"),
                    transform=data_transform["train"])
```
åŠ è½½è®­ç»ƒé›†çš„æ•°æ®ï¼Œå¯ä»¥çœ‹åˆ°é‡Œé¢çš„rootå’Œtransform

`flower_list = train_dataset.class_to_idx` åŠ è½½æ¯ä¸€ä¸ªç±»åˆ«å¯¹åº”çš„ç´¢å¼•å€¼

`cla_dict = dict((val, key) for key, val in flower_list.items())`
å°†`ç±»åˆ« ç´¢å¼•`å˜æˆ`ç´¢å¼• ç±»åˆ«`

```python
json_str = json.dumps(cla_dict, indent=4)
with open('class_indices.json', 'w') as json_file:
    json_file.write(json_str)
```

`json.dumps()`: è¿™æ˜¯ Python çš„ json æ¨¡å—ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå°† Python å¯¹è±¡ï¼ˆå¦‚å­—å…¸ã€åˆ—è¡¨ç­‰ï¼‰è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²

`cla_dict`: è¿™æ˜¯ä¸€ä¸ª Python å­—å…¸å¯¹è±¡ï¼ŒåŒ…å«äº†ä½ æƒ³è¦è½¬æ¢ä¸º JSON æ ¼å¼çš„æ•°æ®

`indent=4`: è¿™æ˜¯ä¸€ä¸ªå¯é€‰å‚æ•°ï¼Œç”¨äºæŒ‡å®š JSON å­—ç¬¦ä¸²çš„ç¼©è¿›çº§åˆ«ã€‚è¿™é‡Œè®¾ç½®ä¸º 4ï¼Œæ„å‘³ç€ç”Ÿæˆçš„ JSON å­—ç¬¦ä¸²å°†ä½¿ç”¨ 4 ä¸ªç©ºæ ¼è¿›è¡Œç¼©è¿›ï¼Œä»è€Œä½¿å…¶æ›´å…·å¯è¯»æ€§

```python
w = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  
# number of workers
print('Using {} dataloader workers every process'.format(nw))
```
`os.cpu_count()` è¿”å›å½“å‰ç³»ç»Ÿçš„ CPU æ ¸å¿ƒæ•°é‡ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ çš„è®¡ç®—æœºæœ‰ 8 ä¸ªæ ¸å¿ƒï¼Œè¿™ä¸ªå‡½æ•°å°†è¿”å› 8ã€‚

`atch_size if batch_size > 1 else 0` è¿™éƒ¨åˆ†ä»£ç æ£€æŸ¥ `batch_size` çš„å€¼ï¼šå¦‚æœ `batch_size` å¤§äº 1ï¼Œåˆ™è¿”å› `batch_size`ï¼›å¦‚æœ `batch_size` å°äºæˆ–ç­‰äº 1ï¼Œåˆ™è¿”å› 0ã€‚

`8` è¿™æ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œè¡¨ç¤ºå·¥ä½œçº¿ç¨‹çš„æœ€å¤§æ•°é‡é™åˆ¶ä¸º `8`

`min([...])`å‡½æ•°å–ä¸Šè¿°ä¸‰ä¸ªå€¼ä¸­çš„æœ€å°å€¼ï¼Œç¡®å®šæœ€ç»ˆçš„å·¥ä½œçº¿ç¨‹æ•°é‡
```python
train_loader = torch.utils.data.DataLoader(
                            train_dataset,
                            batch_size=batch_size, shuffle=True,
                            num_workers=nw)

validate_dataset = datasets.ImageFolder(
                            root=os.path.join(image_path, "val"),
                            transform=data_transform["val"])
val_num = len(validate_dataset)
validate_loader = torch.utils.data.DataLoader(
                            validate_dataset,
                            batch_size=4, shuffle=False,
                            num_workers=nw)
```
è½½å…¥è®­ç»ƒé›†ï¼Œç„¶åè½½å…¥éªŒè¯é›†ï¼Œval_numéªŒè¯é›†æ–‡ä»¶ä¸ªæ•°ï¼Œè®­ç»ƒé›†æ–‡ä»¶ä¸ªæ•°`train_num = len(train_dataset)`åœ¨å‰é¢
```python
    # test_data_iter = iter(validate_loader)
    # test_image, test_label = test_data_iter.next()
    test_data_iter = iter(validate_loader)
    test_image, test_label = next(test_data_iter)

    
    def imshow(img):
        img = img / 2 + 0.5  # unnormalize
        npimg = img.numpy()
        plt.imshow(np.transpose(npimg, (1, 2, 0)))
        plt.show()
    
    print(' '.join('%5s' % cla_dict[test_label[j].item()] for j in range(4)))
    imshow(utils.make_grid(test_image))
```
è¯»å–å›¾ç‰‡é‚£çš„ä»£ç ç”¨.nextæ–¹æ³•ç°åœ¨å¥½åƒä¼šæŠ¥é”™äº†`AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute 'next'`ï¼Œæ”¹ä¸€ä¸‹ç”¨next()å‡½æ•°å°±å¥½äº†

```python
net.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters(), lr=0.0002)
```
é€‰æ‹©GPUè¿˜æ˜¯CPUï¼Œå®šä¹‰æŸå¤±å‡½æ•°ï¼Œé€‰æ‹©ä¼˜åŒ–å™¨ï¼Œæ²¡ä»€ä¹ˆå¥½è¯´çš„

`net.train()` å¯ç”¨dropoutæ–¹æ³•

`net.eval()` å…³é—­dropoutæ–¹æ³•

è®°å½•è®­ç»ƒæ—¶é—´
```python
t1=time.perf_couter()
print(time.perf_counter()-t1)
```

# ä¸‰ã€é¢„æµ‹çš„ä»£ç 
`img = torch.unsqueeze(img, dim=0)` æ‰©å……ç»´åº¦ï¼Œåœ¨æœ€å‰é¢æ·»åŠ batchç»´åº¦

`output = torch.squeeze(model(img.to(device))).cpu()`
è¿™é‡Œä½¿ç”¨squeezeå‹ç¼©æ‰äº†ç¬¬ä¸€ä¸ªç»´åº¦

`model = AlexNet(num_classes=5).to(device)`
è¿™é‡Œçš„num_classeså‚æ•°ï¼Œåœ¨è‡ªå·±è®­ç»ƒå…¶ä»–æ•°æ®é›†çš„æ—¶å€™è¦æ”¹ä¸€ä¸‹

`predict_cla = torch.argmax(predict).numpy()`
ä½¿ç”¨argmaxè·å–æ¦‚ç‡æœ€å¤§çš„ç´¢å¼•å€¼

å…¶ä½™ä»£ç éƒ½æ¯”è¾ƒç®€å•ï¼Œä¸è¯´äº†ï¼ŒæŠŠé¢„æµ‹çš„ä»£ç æ”¾ä¸‹é¢ï¼Œå†™äº†ç‚¹æ³¨é‡Šï¼š
```python
def main():
    device = torch.device("cuda:0" 
    if torch.cuda.is_available() else "cpu") #é€‰æ‹©GPUè¿˜æ˜¯CPU

    data_transform = transforms.Compose( #æ„é€ é¢„å¤„ç†å‡½æ•°
        [transforms.Resize((224, 224)),
         transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    # load image
    img_path = "../test.jpg" #åŠ è½½æµ‹è¯•å›¾ç‰‡
    assert os.path.exists(img_path), "file: '{}' dose not exist."
    .format(img_path)
    img = Image.open(img_path)

    plt.imshow(img) #ç®€å•å±•ç¤ºä¸€ä¸‹æµ‹è¯•å›¾ç‰‡
    # [N, C, H, W]
    img = data_transform(img) #å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
    # expand batch dimension æ‰©å……ç»´åº¦
    img = torch.unsqueeze(img, dim=0) #åœ¨å›¾ç‰‡æ•°æ®æœ€å‰é¢åŠ ä¸€ä¸ªbatchç»´åº¦

    # read class_indict
    json_path = "./class_indices.json"  
    # è¯»å–ä¸€ä¸‹jsonæ–‡ä»¶é‡Œé¢çš„åˆ†ç±»ä¿¡æ¯åˆ°class_indicté‡Œè¾¹å»
    assert os.path.exists(json_path), "file: '{}' dose not exist."
    .format(json_path)

    with open(json_path, "r") as f:
        class_indict = json.load(f)

    # create model
    model = AlexNet(num_classes=5).to(device) 
    #è¿™é‡Œçš„num_classeså‚æ•°ï¼Œåœ¨è‡ªå·±è®­ç»ƒå…¶ä»–æ•°æ®é›†çš„æ—¶å€™è¦æ”¹ä¸€ä¸‹

    # load model weights
    weights_path = "./AlexNet.pth" #åŠ è½½ä¸€ä¸‹æ¨¡å‹æƒé‡
    assert os.path.exists(weights_path), "file: '{}' dose not exist
    .".format(weights_path)
    model.load_state_dict(torch.load(weights_path))

    model.eval() #å…³é—­dropout
    with torch.no_grad():
        # predict class
        output = torch.squeeze(model(img.to(device))).cpu() #ç®—ä¸€ä¸‹è¾“å‡º
        predict = torch.softmax(output, dim=0) #ç®—ä¸€ä¸‹é¢„æµ‹å€¼
        predict_cla = torch.argmax(predict).numpy() 
        #æŠŠé¢„æµ‹å€¼æœ€å¤§çš„ç´¢å¼•æ‹¿å‡ºæ¥ï¼Œå› ä¸ºåœ¨ä¸‹é¢æˆ‘ä»¬æƒ³é€šè¿‡pltè¾“å‡ºä¸€ä¸‹

    print_res = "class: {}   prob: {:.3}"
                .format(class_indict[str(predict_cla)], #classç±»åˆ« probæ¦‚ç‡
                        predict[predict_cla].numpy())
    plt.title(print_res)
    for i in range(len(predict)): #åœ¨ç»ˆç«¯æ‰“å°æ‰€æœ‰çš„ç±»åˆ«å’Œå¯¹åº”çš„æ¦‚ç‡
        print("class: {:10}   prob: {:.3}"
               .format(class_indict[str(i)],
                        predict[i].numpy()))
    plt.show()

```
